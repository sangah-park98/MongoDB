GET _cat
# 모든 인덱스 보기
GET _cat/indices
GET _cat/indices?v

# 인덱스(테이블) 만들기
# PUT 인덱스이름
PUT index1
PUT index2

# 개별 인덱스 확인하기
GET index1 
GET index2
# 개별 인덱스 삭제하기, 인덱스가 삭제되면서 저장된 모든 도큐먼트도 같이 삭제된다.
# DELETE 인덱스이름
DELETE index1
DELETE index2

# 인덱스를 만들면서 데이터 입력하기
# 인덱스가 없으면 인덱스를 만들고 도큐먼트를 입력하고 인덱스가 있으면 기존 인덱스에 도큐먼트를 입력한다.
# 도큐먼트를 인덱스에 저장(포함)시키는 것을 인덱싱이라고 한다.
# 인덱싱한 후 GET index을 눌러보면 알아서 오토 매핑이 되어있다.
# PUT index2/_doc/1 
# => _doc를 쓰면 테이블도 만들고 데이터도 넣겠다는 뜻
#     1은 record의 고유 아이디를 의미한다.
# 도큐먼트는 JSON 형식으로 입력한다.
# PUT 인덱스이름/아이디이름
PUT index2/_doc/1
{
  "name": "mike",
  "age": 25,
  "gender": "male"
}

# 기존 인덱스에 도큐먼트 입력하기
# 새롭게 counrty 필드를 추가하고 기존에 있던 age, gender 필드는 사용하지 않았지만 문제없이 추가된다.
PUT index2/_doc/2
{
  "name": "kim",
  "country": "france"
}
# 잘못된 도큐먼트 입력하기
# age 필드는 long 타입으로 매핑됐는데 text 타입으로 입력했다.
# 관계형 데이터베이스라면 오류가 발생하지만 엘라스틱 서치는 유연하게 대응하기 때문에 타입을 변환해서 저장한다.
PUT index2/_doc/3
{
  "name": "jane",
  "age": "20",
  "gender": "female"
}

# 아이디를 이용해서 인덱스에 저장된 개별 도큐먼트 조회하기
# GET 인덱스이름/_doc/아이디
GET index2/_doc/1
GET index2/_doc/2
GET index2/_doc/3

# 엘라스틱 서치가 제공하는 쿼리(DSL, Domain Specific Language)를 이용해 도큐먼트 읽어오기
# 인덱스에 저장된 모든 도큐먼트를 읽어오기
GET index2/_search

# 도큐먼트 수정하기
# PUT 인덱스이름/_doc/아이디
# PUT 명령을 존재하지 않는 아이디로 실행하면 도큐먼트가 입력되고 존재하는 아이디로 실행하면 도큐먼트가 수정된다.

PUT index2/_doc/1
{
  "name": "park",
  "age": 45,
  "gender": "female"
}

# PUT 명령으로 도큐먼트를 수정하면 기존의 저장되었던 모든 필드가 삭제되고 새로 입력하는 내용으로 도큐먼트가 덮어쓰기가 된다.
PUT index2/_doc/2
{
  "name": "hong"
}

# POST 명령으로 도큐먼트를 수정하면 저장되어 있던 모든 도큐먼트는 그대로 유지되고 수정하는 도큐먼트만 변경된다.
# POST 인덱스이름/_update/아이디
# {} 내부에 바로 수정하려는 내용을 쓰면 안되고 doc 블록을 만들고 doc 블록 내부에 수정할 내용을 써야한다.
POST index2/_update/3
{
  "doc": {
    "name": "choi"  
  }
}

# 아이디를 이용해서 인덱스에 저장된 개별 도큐먼트 삭제하기
# DELETE 인덱스이름/_doc/아이디
DELETE index2/_doc/2


# 도큐먼트 CRUD 동작을 할 때 REST API를 호출해 하나하나 도큐먼트를 요청하는 것보다 벌크로 한번에 요청하는 것이 효율적이다.
# 벌크는 도큐먼트 읽기는 지원하지 않고 생성, 수정, 삭제만 지원한다.
# 벌크 데이터 형식은 삭제(delete)는 한줄로 작성하고 나머지 작업(index, create, update)은 두줄로 작성한다.

# 벌크(더미) 데이터
# POST _bulk
# {"index": {"index": "인덱스이름", "_id": "아이디"}}
# index는 벌크 데이터로 입력되는 아이디가 존재하면 기존 데이터를 수정한다.
POST _bulk
{"index": {"_index": "index2", "_id": "4"}}
{"name": "kang", "age":30, "gender": "male"}


# POST _bulk
# {"create": {"index": "인덱스이름", "_id": "아이디"}}
# {"field": "value", ...}
POST _bulk
{"create": {"_index": "index2", "_id": "5"}}
{"name": "song", "age": 35, "gender": "female"}
# create는 벌크 데이터로 입력되는 아이디가 존재하면 에러가 발생한다.


# 벌크 데이터 수정하기
# POST _bulk
# {"update": {"index": "인덱스이름", "_id": "아이디"}}
# {"doc": {"field": "value", ...}}
POST _bulk
{"update": {"_index": "index2", "_id": "4"}}
{"doc": {"name": "jang"}}


# 벌크 데이터 삭제하기
# POST _bulk
#{"delete" : {"_index": "인덱스이름", "_id": "아이디"}}
POST _bulk
{"delete": {"_index": "index2", "_id": "5"}}

GET index2/_doc/4
GET index2/_doc/5

# ------------------------------------------------------------------
# 매핑(Mapping)
# 관계형 데이터베이스의 스키마와 같은 역할을 하는 것을 매핑이라 한다.
# 엘라스틱 서치가 검색 엔진으로 전문검색과 대용량 데이터를 빠르게 실시간 검색할 수 있는 이유는 매핑이 되어있기 때문인데 매핑을 엘라스틱 서치가 자동으로 하면 다이내믹(오토) 매핑이라 하고, 사용자가 직접 설정하면 명시적 매핑이라 한다.
# 엘라스틱 서치는 문자열 타입을 text와 keyword 타입으로 나눌 수 있는데 전문 검색을 활용하려면 이 두 가지 타입을 이해하고 있어야 한다.

# 인덱스 매핑 정보만 확인하기
GET index2/_mapping

# 인덱스를 만들면서 명시적 매핑 지정하기
# 이미 인덱스 만들고서 다시 재실행하면 error가 뜨므로 delete하고 다시 재실행 해야한다.
# PUT 인덱스이름
# {
#  "mappings": {
#    "properties": {
#       "필드이름": {
#         "type"  : "필드타입"
#       }
#       , ...
#     }
#   }
# }

PUT index3
{
  "mappings": {
    "properties": {
      "name" : {
          "type" : "text"
      },
      "age": {
        "type": "short"
      },
      "gender": {
        "type": "keyword"
      }
    }
  }
}
GET index3/_mapping
DELETE index3

# 다이내믹 매핑 타입
# boolean(논리값), float(실수), long(정수), object(객체), text, keyword(문자열)

# 명시적 매핑 타입
# 텍스트
#   text: 전문 검색, 텍스트 분석기가 텍스트를 작은 단위로 분리한다.
#   keyword: 정렬 또는 집계, 텍스트를 분리하지 않고 원문을 전체로 인덱싱한다.
# 날짜
#   date: 날짜/시간 데이터
# 부호가 있는 정수(음수와 양수 모두 취급 가능, 고정 소수점)
#   byte: 8비트
#   short: 16비트
#   integer: 32비트
#   long: 64비트
# 실수(부동/유동의 소수점 실수)
#   scaled flaot: float 데이터의 특정 값을 곱해서 정수형으로 바꾼 데이터
#   half_float: 16비트
#   float: 32비트 실수
#   double: 64비트 실수
# 논리
#   boolean: true 또는 false만 값으로 가진다.
# IP 주소
#   ip: ipv4 또는 ipv6 타입의 ip 주소를 입력한다.
# 위치 정보
#   geo-point: 하나의 위치포인트(위도, 경도)
#   geo-shape: 하나의 위치 포인트가 아닌 임의의 지형
# 범위 설정
#   integer_range, long_range: 정수형 범위
#   float_range, double_range: 실수형 범위
#   ip_range: ip 주소 범위
#   date_range: 날짜 범위
# 객체형
#   object: 계층 구조를 가지는 형태로 필드 안에 다른 필드들이 들어갈 수 있다.
# 배열형
#   nested: 배열형 객체
#   join: 부모/자식 객체를 표현할 수 있다.

# text 타입
# 일반적으로 문장을 저장하는 매핑 타입으로 사용된다.
# 무조건적인 강제성은 없지만 일반적으로 문장 또는 여러 단어가 나열되는 문자열은 text 타입으로 지정한다.

POST _analyze 
{
  "analyzer": "standard",
  "text": "We offer solutions for enterprise search, observability, and security that are built on a single, flexible technology stack that can be deployed anywhere"
}

# text 타입으로 지정된 문자열은 분석기(analyzer)에 의해 토큰(token)으로 분리되고
# 분리된 토큰들은 인덱싱되는데 이를 역인덱싱(inverted indexing)이라 한다.
# 이때, 역인덱싱에 저장된 토큰들을 용어(term)이라고 한다!

# text 타입을 가지는 인덱스 생성
PUT text_index
{
  "mappings": {
    "properties": {
      "contents" : {
        "type": "text"
      }
    }
  }
}
GET text_index/_mapping

PUT text_index/_doc/1
{
  "contents": "beautiful day"
}
GET text_index/_doc/1

PUT text_index/_doc/2
{
  "contents": "beautiful moment"
}
GET text_index/_doc/2

# text_index 인덱스에 match라는 전문 검색 쿼리 실행
GET text_index/_search
{
  "query": {
    "match": {
      "contents": "beautiful"
    }
  }
}

# keyword 타입을 가지는 인덱스 생성
PUT keyword_index
{
  "mappings": {
    "properties": {
      "contents": {
        "type": "keyword"
      }
    }
  }
}
GET keyword_index/_mapping

PUT keyword_index/_doc/1
{
  "contents": "beautiful day"
}
GET keyword_index/_doc/1

PUT keyword_index/_doc/2
{
  "contents": "beautiful moment"
}
GET keyword_index/_doc/2


# keyword_index 인덱스에 match라는 전문 검색 쿼리 실행
GET keyword_index/_search
{
  "query": {
    "match": {
      "contents": "beautiful moment"
    }
  }
}

# 멀티 필드
# 멀티 필드는 단일 필드 입력에 대해 여러 하위 필드를 정의한다.
# 문자열의 경우 전문 검색이 필요하면서 정렬 또는 집계로 필요한 경우가 있다.
# 멀티 필드를 만들기 위해서는 fields라는 파라미터를 사용한다.
# 

# 멀티 필드를 가지는 인덱스 생성
# message는 단일 필드, contents는 멀티 필드
# fields라는 파라미터에 "keyword"라는 필드 이름을 사용했는데 반드시 "keyword"라는 필드 이름을 사용하지 않고 "abc"와 같은 필드 이름을 사용해도 무관하지만 통상적으로 "keyword"라는 필드 이름을 많이 사용한다.
PUT multifield_index
{
  "mappings": {
    "properties": {
      "message": {
        "type": "text"
      },
      "contents": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword"
          }
        }
      }
    }
  }
}
GET multifield_index/_mapping
DELETE multifield_index

PUT multifield_index/_doc/1
{
  "message": "1 document",
  "contents": "beautiful day"
}
GET multifield_index/_doc/1

PUT multifield_index/_doc/2
{
  "message": "2 document",
  "contents": "beautiful moment"
}
GET multifield_index/_doc/2

PUT multifield_index/_doc/3
{
  "message": "3 document",
  "contents": "wonderful day"
}
GET multifield_index/_doc/3

PUT multifield_index/_doc/4
{
  "message": "4 document",
  "contents": "wonderful day"
}
GET multifield_index/_doc/4
GET multifield_index/_search

# mulltified_index 인덱스에 match라는 전문 검색 쿼리 실행
GET multifield_index/_search
{
  "query": {
    "match": {
      "message": "beautiful"
    }
  }
}
GET multifield_index/_search
{
  "query": {
    "match": {
      "contents": "beautiful"
    }
  }
}

# mulltified_index 인덱스에 term이라는 용어 검색 쿼리 실행
# 이번에는 contents 필드의 keyword 타입으로 검색해보자. keyword 타입은 contents 필드의 하위 필드이므로 조금 다른 방식의 접근이 필요하다.
# "contents"는 contents 필드를 의미하므로 contents 뒤에 keyword를 추가해서 하위 필드를 참조할 수 있다. 
GET multifield_index/_search
{
  "query": {
    "term": {
      "contents.keyword": "wonderful day"
    }
  }
}

# multifieid_index 인덱스에 aggs라는 집계 쿼리 실행
GET multifield_index/_search
{
  "aggs": {
    "contents": {
      "terms": {
        "field": "contents.keyword",
        "size": 10
      }
    }
  }
}
# "contents.keyword"로 지정했으므로 값이 같은 데이터끼리 그룹화가 된다.
# "size"는 집계를 계산하는데 사용된 데이터를 출력할 개수를 지정한다.

# 인덱스 템플릿
# 인덱스 템플릿은 설정이 동일한 인덱스를 매번 일일이 작성하는 것은 비효율적일 뿐만 아니라 실수를 유발할 수 있기 때문에 주로 설정이 동일한 복수의 인덱스를 만들 때 사용한다.

# 모든 인덱스 템플릿을 확인한다.
GET _index_template
# 특정 인덱스 템플릿을 확인한다.
# GET _index_template/인덱스템플릿이름
GET _index_template/ilm-history
# 확인할 인덱스 템플릿 이름에 와일드카드 문자(*)를 사용할 수 있다.
GET _index_template/.ml*

# 인덱스 템플릿 만들기
# PUT _index_template/인덱스템플릿이름
# {
#   mapping과 setting을 사용해서 인덱스 템플릿 설정 정의
# }

# 인덱스 템플릿이 적용되지 않은 인덱스
PUT test_index1
GET test_index1
DELETE test_index1

PUT test_index1/_doc/1
{
  "name": "kim",
  "age": 99,
  "gender": "male"
}
GET test_index1/_doc/1
GET test_index1/_mapping

# index_patterns 파라미터
# 새로 만들어지는 인덱스 중에 인덱스 이름이 지정한 인덱스 패턴과 매칭되는 경우 이 템플릿을 적용한다.

# 인덱스 템플릿을 만들기 전에 존재하던 인덱스들은 새로 작성된 인덱스 템플릿의 index_patterns 파라미터에 지정된 패턴과 이름이 일치하더라도 인덱스 템플릿이 적용되지 않는다.
# 즉, 인덱스 템플릿이 생성된 시점 이후에 작성되는 인덱스에 인덱스 템플릿이 적용된다.
# priority 파라미터
# 인덱스 생성시 인덱스 이름에 매칭되는 인덱스 템플릿이 2개 이상일 경우 인덱스 템플릿이 적용되는 우선순위를 정한다. 숫자가 높은 템플릿이 먼저 적용된다.

# template 파라미터
# 새로 생성되는 인덱스에 적용되는 mappings과 settings을 설정한다.
PUT _index_template/test_template
{
  "index_patterns": ["test_*"], 
  "priority": 1,
  "template": {
    "settings": {
      "number_of_shards": 3,
      "number_of_replicas": 1
    },
    "mappings": {
      "properties": {
        "name": {"type": "text"},
        "age": {"type": "short"},
        "gender": {"type": "keyword"}
      }
    }
  }
}

GET _index_template/test_template
GET _index_template/test_*

# 인덱스 템플릿 삭제하기
# DELETE _index_template/인덱스템플릿이름
DELETE _index_template/test_template

# 인덱스 템플릿이 적용된 인덱스
PUT test_index2
GET test_index2
DELETE test_index2

PUT test_index2/_doc/1
{
  "name": "kim",
  "age": 99,
  "gender": "male"
}
GET test_index2/_doc/1
GET test_index2/_mapping

# 인덱스 템플릿의 index_patterns과 일치하지 않으면 인덱스 템플릿이 적용되지 않는다.
PUT testindex2
GET testindex2
DELETE testindex2

PUT testindex2/_doc/1
{
  "name": "kim",
  "age": 99,
  "gender": "male"
}
GET testindex2/_doc/1
GET testindex2/_mapping

# 인덱스 템플릿이 적용된 인덱스에 인덱스 템플릿 매핑값과 다른 데이터가 입력되면 웬만하면 오토 매핑으로 처리를 하지만 불가능 할 경우 에러가 발생한다.
# "99"는 short 타입으로 mapper_parsing이 가능하여 정상적으로 처리
PUT test_index2/_doc/2
{
  "name": "lee",
  "age": "99",
  "gender": "female"
}
GET test_index2/_doc/2
GET test_index2/_mapping

# "99 years"는 short 타입으로 mapper_parsing이 불가능하여 정상적으로 처리 X
PUT test_index2/_doc/3
{
  "name": "choi",
  "age": "99 years",
  "gender": "male"
}

# priority에 지정한 인덱스 템플릿 적용 우선순위 확인
PUT _index_template/multi_template1
{
  "index_patterns": ["mulit_*"],
  "priority": 1,
  "template": {
    "mappings": {
      "properties": {
        "age": {"type": "integer"},
        "name": {"type": "text"}
      }
    }
  }
}
DELETE _index_template/multi_template1

PUT _index_template/multi_template2
{
  "index_patterns": ["multi_data*"],
  "priority": 2,
  "template": {
    "mappings": {
      "properties": {
        "age": {"type": "short"},
        "name": {"type": "keyword"}
      }
    }
  }
}
DELETE _index_template/multi_template2

GET _index_template/multi_*

# 만들려는 인덱스의 이름이 multi_data_index이므로 multi_template1 인덱스 템플릿의 index_pattern인 "multi_*"에 해당되고 multi_template2 인덱스 템플릿의 index_pattern인 "multi_data"에도 해당된다.
PUT multi_data_index 
DELETE multi_data_index 

# multi_template1 인덱스 템플릿의 priority는 1이고 multi_template2 인덱스 템플릿의 priority는 2로 설정되었기 때문에 priority가 크게 지정된 인덱스 템플릿이 적용된다.
GET multi_data_index/_mapping

# 만들려는 인덱스 이름이 multi_sample_index이므로 multi_template1 인덱스 템플릿의 index_pattern인 "multi_*"에 해당되고 multi_template2 인덱스 템플릿의 index_pattern인 "multi_data"에도 해당되지 않기 때문에 priority와 상관없이 multi_template1이 적용된다.
PUT multi_sample_index
GET multi_sample_index/_mapping

# 다이내믹 템플릿
# 다이내믹 템플릿은 매핑을 다이내믹하게 지정하는 템플릿 기술로 로그 시스템같은 비정형화 된 데이터이다.
# 비정형화 된 데이터는 데이터의 구조를 알 수 없기 때문에 필드 타입을 정확히 정의하기 힘들고 필드의 개수를 정할 수 없는 경우도 있다.
# 다이내믹 템플릿은 매핑을 정확하게 할 수 없거나 대략적인 데이터 구조만 알고 있을 때 사용할 수 있는 방법이다.

# 다이내믹 매핑을 적용한 인덱스 생성
# 인덱스를 만들 때 dynamic_templates를 추가하면 다이내믹 템플릿을 추가할 수 있다.
# my_string_fields는 사용자가 임의로 정한 다이나믹 템플릿의 이름이다. 
# match_mapping_type 파라미터
# 다이내믹 템플릿을 적용할 데이터 유형을 지정해서 다이내믹 매핑의 조건 역할을 한다.
PUT dynamic_index1
{
  "mappings": {
    "dynamic_templates": [
      {
        "my_string_fields": {
          "match_mapping_type": "string", 
          "mapping": {"type": "keyword"}
          
        }
      }
    ]
  }
}
GET dynamic_index1/_mapping
DELETE dynamic_index1

# 문자열과 숫자 데이터를 넣어서 다이나믹 템플릿 매핑 결과를 확인한다.
PUT dynamic_index1/_doc/1
{
  "name": "kim",
  "age": 20
}
GET dynamic_index1/_doc/1

PUT dynamic_index1/_doc/2
{
  "name": "lee",
  "age": 30,
  "gender": "female"
}
GET dynamic_index1/_doc/2
# -------------------------------------------------------------------

# match 파라미터
# 필드 이름이 패턴과 일치할 경우 매핑 타입으로 변경한다.
# unmatch 파라미터
# match 패턴과 일치하는 경우에 제외할 패턴을 설정한다. 

PUT dynamic_index2
{
  "mappings": {
    "dynamic_templates": [
      {
        "my_long_fields": {
          "match": "long_*",
          "unmatch": "*_text",
          "mapping": {"type": "long"}
        }
      }
    ]
  }
}
DELETE dynamic_index2
GET dynamic_index2/_mapping

# 필드 이름에 따른 다이내믹 템플릿 매핑 결과를 확인한다.
PUT dynamic_index2/_doc/1
{
  "long_num": "5"
}
GET dynamic_index2/_doc/1

# long_text 필드는 match에 적어둔 패턴에 매칭되지만 unmatch에 적은 패턴에도 매칭되기 때문에 integer 타입으로 매칭되지 않고 멀티 필드로 다이나믹 매칭된다.
PUT dynamic_index2/_doc/2
{
  "long_num": "50",
  "long_text": "100"
}
GET dynamic_index2/_doc/2


# 캐릭터 필터
# 입력받은 문자열을 변경하거나 불필요한 문자들을 제거한다.

# 토크나이저
# 문자열을 토큰으로 분리한다. 분리할 때 토큰의 순서나 시작, 끝 위치도 기록한다.

# 토큰 필터
# 분리된 토큰 필터 작업을 한다. 대소문자 구분, 형태소 분석 등의 작업을 한다.

# 분석기
# 엘라스틱 서치는 전문 검색을 지원하기 위해 역인덱싱 기술을 사용한다.
# 역인덱싱이란 문자열을 토큰화(단어 단위로 나눈다.)하고 인덱싱하는데 이를 역인덱싱이라고 한다.
# 책의 앞부분의 목차와 달리 역인덱싱은 책 뒷부분에 어떤 단어가 책의 몇 페이지에 나와 있는지를 알려주는 색인(인덱스, 찾아보기)과 비슷하다고 볼 수 있다.
# 분석기는 역인덱싱을 지원하기 위해서 캐릭터 필터, 토크나이저, 토큰 필터로 구성된 분석기 모듈을 가지고 있고 토크나이저는 반드시 포함해야 한다.
# 분석기는 토크나이저를 이용해 필터링 된 문자열을 자르게 되는데, 이때 잘린 단위를 토큰이라 하고 이러한 토큰들은 복수의 토큰 필터를 거치며 정제된 후 최종적으로 역인덱싱에 저장되는 상태의 토큰이 되는데 이를 용어(term)라고 한다.

# 분석기 사용법은 analyzer 파라미터에 사용할 분석기를 입력하고 text 파라미터에 분석할 문자열을 입력하면 된다.
# 종류에는 stop, standard, simple, whitespace 분석기가 있다.

# 1. stop 분석기
# simple 분석기와 비슷하지만 스톱 필터가 포함되어 있어서 "the"가 제거되었다.
# 스톱 필터는 불용어(데이터 집합에 출현하는 빈도는 매우 높지만 의미가 없는 단어) 처리를 한다.
POST _analyze 
{
  "analyzer": "stop",
  "text": "The 10 most loving dog breeds."
}
# [most, loving, dog, breeds]

# simple 분석기
# 문자만 토큰화한다. (공백, 숫자, 하이픈, 따옴표 같은 문자는 토큰화하지 않는다.)
POST _analyze 
{
  "analyzer": "simple",
  "text": "The 10 most loving dog breeds."
}
# [the, most, loving, dog, breeds]

# standard 분석기
# 특별한 설정이 없을 경우 엘라스틱 서치가 기본적으로 사용하는 분석기이다.
# 영문법을 기준으로 한 스탠다드 토크나이저와 소문자 변경 필터가 포함되어 있다.
# 공백을 경계로 문장을 토큰화하고 모든 대문자를 소문자로 변경한다.
POST _analyze 
{
  "analyzer": "standard",
  "text": "The 10 most loving dog breeds."
}
# [the, 10, most, loving, dog, breeds]

# whitespace 분석기
# 공백을 경계로 문장을 토큰화하고 화이트 스페이스(\n)는 토큰화하지 않는다.
# 가장 간단한 형태의 분석기로 끝에 '.'까지 나온다.
POST _analyze 
{
  "analyzer": "whitespace",
  "text": "The 10 most loving dog breeds."
}
# [the, 10, most, loving, dog, breeds]

# --------------------------------------------------------------------------

# 토크나이저
# 토크나이저는 문자열을 분리해 토큰화하는 역할을 한다.
# 분석기에 반드시 포함되야 하기 때문에 형태에 맞는 토크나이저 선택이 중요하다.

# standard 토크나이저
# standard 분석기가 사용하는 토크나이저로 특별한 설정이 없으면 기본 토크나이저로 사용된다.
POST _analyze
{
  "tokenizer": "standard",
  "text": "email: elastick@1k-company.com"
}
# [email, elastic, 1k, Company.com]

# lowercase 토크나이저
# 토큰화한 결과를 모두 소문자로 변경한다.
POST _analyze
{
  "tokenizer": "lowercase",
  "text": "email: elastick@1k-company.com"
}
# [email, elastic, 1k, company.com]

# uax_url_email 토크나이저
# url이나 email을 토큰화하는데 강점이 있다.
POST _analyze
{
  "tokenizer": "uax_url_email",
  "text": "email: elastick@1k-company.com"
}
# [email, elastic, 1k, company.com]

# 필터
# 분석기는 하나의 토크나이저와 다수의 필터로 조합된다.
# 분석기에서 필터는 옵션으로 하나 이상을 포함할 수 있지만, 없어도 분석기를 돌리는데 문제가 발생되지 않는다.
# 필터가 없는 분석기는 토크나이저만 이용해서 토큰화 작업을 진행하는데, 엘라스틱 서치에서 제공하는 분석기들은 하나 이상의 필터를 포함하고 있고 필터를 통해 더 세부적인 작업이 가능하다.
# 필터는 단독으로 사용할 수 없고 반드시 토크나이저가 있어야 한다.
POST _analyze
{
  "tokenizer": "standard",
  "text": "The 10 most loving dog breeds."
}

POST _analyze
{
  "tokenizer": "standard",
  "filter": ["lowercase"], 
  "text": "The 10 most loving dog breeds."
}

POST _analyze
{
  "tokenizer": "standard",
  "filter": ["uppercase"], 
  "text": "The 10 most loving dog breeds."
}

# stemmer 필터는 영어 문법을 분석하는 필터로 한글에는 적용되지 않는다.
POST _analyze
{
  "tokenizer": "standard",
  "filter": ["stemmer"], 
  "text": "The 10 most loving dog breeds."
}
# [The, 10, most, love, dog, breeds]


# 커스텀 분석기
# 커스텀 분석기는 엘라스틱 서치에서 제공하는 내장 분석기들 중 원하는 기능을 만족하는 분석기가 없을 때 사용자가 직접 토크나이저, 필터 등을 조합해서 사용할 수 있는 분석기다.
# 커스텀 분석기를 적용한 인덱스 만들기

# settings 파라미터에 analysis 파라미터를 추가하고 analysis 파라미터 내부에 filter 파라미터로 사용자 정의 필터와 analyzer 파라미터로 사용자 정의 분석기를 지정해서 만든다.
# analyzer 파라미터 내부에 분석기 이름(my_analyzer)을 지정하고 type을 custom으로 설정하면 커스텀 분석기라는 것을 의미한다. 
# 분석기에는 반드시 토크나이저가 들어가야 하고 standard 토크나이저로 지정했다.
# 필터는 선택적인 사항이고 캐릭터 필터(char_filter)와 토큰 필터(filter)를 지정할 수 있다.
# 캐릭터 필터는 사용하지 않을 것이므로 []만 입력했고 토큰 필터는 엘라스틱이 제공하는 lowercase와 사용자 정의 필터인 my_stopwords 2개를 사용하기 위해서 ","로 구분해서 나열했다.
# stop 필터는 엘라스틱 서치가 제공하는 불용어를 제외한 추가적인 불용어가 필요할 때 filter 파라미터에 필터 이름(my_stopwords)을 지정하고 type 파라미터에 stopwords 파라미터에 추가 불용어를 입력해서 만든다.

PUT customer_analyzer
{
  "settings": {
    "analysis": {
      "filter": {
        "my_stopwords": {
          "type": "stop",
          "stopwords": ["lions", "cats"]
        }
      },
      "analyzer": {
        "my_analyzer": {
          "type": "custom",
          "char_filter" : [],
          "tokenizer": "standard",
          "filter": ["lowercase", "my_stopwords"]
        }
      }
    }
  }
}
GET customer_analyzer/_analyze
DELETE customer_analyzer

# customer_analyzer 커스텀 분석기 테스트
GET customer_analyzer/_analyze
{
  "analyzer": "my_analyzer",
  "text": "Cats Lions Dogs"
}
























